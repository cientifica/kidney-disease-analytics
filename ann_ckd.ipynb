{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heVCxDh0-Abv"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.kaggle.com/datasets/mahmoudlimam/preprocessed-chronic-kidney-disease-dataset\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uAY8zX2IS-k"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "# Importing the keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRcbTS95IYb8"
      },
      "outputs": [],
      "source": [
        "# Importing the dataset\n",
        "dataset = pd.read_csv('CKD_Preprocessed.csv')\n",
        "X = dataset.iloc[:, 0:24].values\n",
        "y = dataset.iloc[: , 24].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjup-vMHKI1E"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:,1] = labelencoder_X_1.fit_transform(X[:,1])\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:,2] = labelencoder_X_2.fit_transform(X[:,2])\n",
        "ct = ColumnTransformer([(\"Chronic Kidney Disease: yes\", OneHotEncoder(), [1])], remainder = 'passthrough')\n",
        "X = ct.fit_transform(X)\n",
        "X = X[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KFYt7fjKTLa"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into the training set and the test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpYXcoTuKWmr"
      },
      "outputs": [],
      "source": [
        "# Feature Scaling \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIS8eLheKaEC"
      },
      "outputs": [],
      "source": [
        "# Initialising the ANN\n",
        "classifier = Sequential()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WctUd7V8KdLa"
      },
      "outputs": [],
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_shape = (None,None,32)))\n",
        "classifier.add(Dropout(0.1)) # should be below 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tko46SzyNcaS"
      },
      "outputs": [],
      "source": [
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dropout(0.1)) # should be below 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY0ni5qYNfsp"
      },
      "outputs": [],
      "source": [
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYX0OxQFNkMh"
      },
      "outputs": [],
      "source": [
        "# Compiling the ANN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4D0iiFvNnoq",
        "outputId": "898d91ab-2f40-4f9e-8888-ec44dcc17f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/240\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, None, 32) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 32), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 32).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, None, 32) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 32), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 32).\n",
            "14/14 [==============================] - 4s 5ms/step - loss: 0.6925 - accuracy: 0.5969\n",
            "Epoch 2/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.6187\n",
            "Epoch 3/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6854 - accuracy: 0.6187\n",
            "Epoch 4/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6741 - accuracy: 0.6187\n",
            "Epoch 5/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.6187\n",
            "Epoch 6/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.6187\n",
            "Epoch 7/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.6187\n",
            "Epoch 8/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.6187\n",
            "Epoch 9/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.6187\n",
            "Epoch 10/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.6187\n",
            "Epoch 11/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.6187\n",
            "Epoch 12/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.6187\n",
            "Epoch 13/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.6187\n",
            "Epoch 14/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.6187\n",
            "Epoch 15/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.6187\n",
            "Epoch 16/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.6187\n",
            "Epoch 17/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8250\n",
            "Epoch 18/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3588 - accuracy: 0.9406\n",
            "Epoch 19/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.9438\n",
            "Epoch 20/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.9531\n",
            "Epoch 21/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.9719\n",
            "Epoch 22/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.9625\n",
            "Epoch 23/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3224 - accuracy: 0.9625\n",
            "Epoch 24/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.9625\n",
            "Epoch 25/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3153 - accuracy: 0.9469\n",
            "Epoch 26/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.9594\n",
            "Epoch 27/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.9844\n",
            "Epoch 28/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2970 - accuracy: 0.9563\n",
            "Epoch 29/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2901 - accuracy: 0.9594\n",
            "Epoch 30/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2869 - accuracy: 0.9594\n",
            "Epoch 31/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.9656\n",
            "Epoch 32/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2846 - accuracy: 0.9438\n",
            "Epoch 33/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.9688\n",
            "Epoch 34/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2672 - accuracy: 0.9688\n",
            "Epoch 35/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2692 - accuracy: 0.9469\n",
            "Epoch 36/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2581 - accuracy: 0.9750\n",
            "Epoch 37/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.9750\n",
            "Epoch 38/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2530 - accuracy: 0.9719\n",
            "Epoch 39/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.9625\n",
            "Epoch 40/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2495 - accuracy: 0.9531\n",
            "Epoch 41/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.9469\n",
            "Epoch 42/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2363 - accuracy: 0.9656\n",
            "Epoch 43/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2342 - accuracy: 0.9688\n",
            "Epoch 44/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2256 - accuracy: 0.9812\n",
            "Epoch 45/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2313 - accuracy: 0.9594\n",
            "Epoch 46/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2217 - accuracy: 0.9719\n",
            "Epoch 47/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2236 - accuracy: 0.9656\n",
            "Epoch 48/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9594\n",
            "Epoch 49/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2225 - accuracy: 0.9469\n",
            "Epoch 50/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2146 - accuracy: 0.9625\n",
            "Epoch 51/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2132 - accuracy: 0.9531\n",
            "Epoch 52/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2037 - accuracy: 0.9781\n",
            "Epoch 53/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2076 - accuracy: 0.9750\n",
            "Epoch 54/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2044 - accuracy: 0.9656\n",
            "Epoch 55/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2037 - accuracy: 0.9656\n",
            "Epoch 56/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.9844\n",
            "Epoch 57/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1915 - accuracy: 0.9750\n",
            "Epoch 58/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9688\n",
            "Epoch 59/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1850 - accuracy: 0.9906\n",
            "Epoch 60/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1912 - accuracy: 0.9906\n",
            "Epoch 61/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1855 - accuracy: 1.0000\n",
            "Epoch 62/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9969\n",
            "Epoch 63/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1837 - accuracy: 0.9906\n",
            "Epoch 64/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1808 - accuracy: 0.9937\n",
            "Epoch 65/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.9969\n",
            "Epoch 66/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1728 - accuracy: 1.0000\n",
            "Epoch 67/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.9937\n",
            "Epoch 68/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1697 - accuracy: 0.9969\n",
            "Epoch 69/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1646 - accuracy: 1.0000\n",
            "Epoch 70/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1671 - accuracy: 0.9969\n",
            "Epoch 71/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1649 - accuracy: 0.9969\n",
            "Epoch 72/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1649 - accuracy: 0.9969\n",
            "Epoch 73/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 0.9969\n",
            "Epoch 74/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1589 - accuracy: 0.9969\n",
            "Epoch 75/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1536 - accuracy: 1.0000\n",
            "Epoch 76/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1539 - accuracy: 1.0000\n",
            "Epoch 77/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1556 - accuracy: 0.9937\n",
            "Epoch 78/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1574 - accuracy: 0.9937\n",
            "Epoch 79/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1555 - accuracy: 0.9969\n",
            "Epoch 80/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1496 - accuracy: 1.0000\n",
            "Epoch 81/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 0.9969\n",
            "Epoch 82/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1487 - accuracy: 0.9969\n",
            "Epoch 83/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1407 - accuracy: 1.0000\n",
            "Epoch 84/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1439 - accuracy: 1.0000\n",
            "Epoch 85/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9969\n",
            "Epoch 86/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 1.0000\n",
            "Epoch 87/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1359 - accuracy: 1.0000\n",
            "Epoch 88/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1363 - accuracy: 1.0000\n",
            "Epoch 89/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 1.0000\n",
            "Epoch 90/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 1.0000\n",
            "Epoch 91/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1284 - accuracy: 1.0000\n",
            "Epoch 92/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 1.0000\n",
            "Epoch 93/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 1.0000\n",
            "Epoch 94/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.9969\n",
            "Epoch 95/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9969\n",
            "Epoch 96/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1211 - accuracy: 1.0000\n",
            "Epoch 97/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 1.0000\n",
            "Epoch 98/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1279 - accuracy: 0.9937\n",
            "Epoch 99/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9969\n",
            "Epoch 100/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9937\n",
            "Epoch 101/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 1.0000\n",
            "Epoch 102/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 1.0000\n",
            "Epoch 103/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 1.0000\n",
            "Epoch 104/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1203 - accuracy: 0.9937\n",
            "Epoch 105/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9969\n",
            "Epoch 106/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 1.0000\n",
            "Epoch 107/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 1.0000\n",
            "Epoch 108/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 1.0000\n",
            "Epoch 109/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9969\n",
            "Epoch 110/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1049 - accuracy: 1.0000\n",
            "Epoch 111/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.9969\n",
            "Epoch 112/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9969\n",
            "Epoch 113/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9937\n",
            "Epoch 114/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 1.0000\n",
            "Epoch 115/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 1.0000\n",
            "Epoch 116/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1049 - accuracy: 0.9969\n",
            "Epoch 117/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 1.0000\n",
            "Epoch 118/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 1.0000\n",
            "Epoch 119/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9937\n",
            "Epoch 120/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 1.0000\n",
            "Epoch 121/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 1.0000\n",
            "Epoch 122/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9969\n",
            "Epoch 123/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 1.0000\n",
            "Epoch 124/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1003 - accuracy: 0.9969\n",
            "Epoch 125/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9969\n",
            "Epoch 126/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0920 - accuracy: 1.0000\n",
            "Epoch 127/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 1.0000\n",
            "Epoch 128/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.9969\n",
            "Epoch 129/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0929 - accuracy: 0.9969\n",
            "Epoch 130/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0925 - accuracy: 0.9969\n",
            "Epoch 131/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9969\n",
            "Epoch 132/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 1.0000\n",
            "Epoch 133/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0931 - accuracy: 0.9969\n",
            "Epoch 134/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 1.0000\n",
            "Epoch 135/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 1.0000\n",
            "Epoch 136/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 1.0000\n",
            "Epoch 137/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0834 - accuracy: 1.0000\n",
            "Epoch 138/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9969\n",
            "Epoch 139/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9969\n",
            "Epoch 140/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 1.0000\n",
            "Epoch 141/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0898 - accuracy: 0.9937\n",
            "Epoch 142/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9969\n",
            "Epoch 143/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 1.0000\n",
            "Epoch 144/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 1.0000\n",
            "Epoch 145/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 1.0000\n",
            "Epoch 146/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 1.0000\n",
            "Epoch 147/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0810 - accuracy: 0.9969\n",
            "Epoch 148/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 1.0000\n",
            "Epoch 149/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9969\n",
            "Epoch 150/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 1.0000\n",
            "Epoch 151/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 1.0000\n",
            "Epoch 152/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9969\n",
            "Epoch 153/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9969\n",
            "Epoch 154/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 1.0000\n",
            "Epoch 155/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 1.0000\n",
            "Epoch 156/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9969\n",
            "Epoch 157/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 158/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 1.0000\n",
            "Epoch 159/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9969\n",
            "Epoch 160/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0694 - accuracy: 1.0000\n",
            "Epoch 161/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 1.0000\n",
            "Epoch 162/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 1.0000\n",
            "Epoch 163/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 1.0000\n",
            "Epoch 164/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 1.0000\n",
            "Epoch 165/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 1.0000\n",
            "Epoch 166/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 1.0000\n",
            "Epoch 167/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0652 - accuracy: 1.0000\n",
            "Epoch 168/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9969\n",
            "Epoch 169/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 1.0000\n",
            "Epoch 170/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 1.0000\n",
            "Epoch 171/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 1.0000\n",
            "Epoch 172/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 1.0000\n",
            "Epoch 173/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9937\n",
            "Epoch 174/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9969\n",
            "Epoch 175/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9969\n",
            "Epoch 176/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.9969\n",
            "Epoch 177/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 1.0000\n",
            "Epoch 178/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9937\n",
            "Epoch 179/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9937\n",
            "Epoch 180/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 1.0000\n",
            "Epoch 181/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 1.0000\n",
            "Epoch 182/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0586 - accuracy: 1.0000\n",
            "Epoch 183/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 1.0000\n",
            "Epoch 184/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 1.0000\n",
            "Epoch 185/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 1.0000\n",
            "Epoch 186/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 1.0000\n",
            "Epoch 187/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 1.0000\n",
            "Epoch 188/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9969\n",
            "Epoch 189/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 1.0000\n",
            "Epoch 190/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 1.0000\n",
            "Epoch 191/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9937\n",
            "Epoch 192/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 1.0000\n",
            "Epoch 193/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 194/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 1.0000\n",
            "Epoch 195/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9969\n",
            "Epoch 196/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 1.0000\n",
            "Epoch 197/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 198/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 199/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 1.0000\n",
            "Epoch 200/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 1.0000\n",
            "Epoch 201/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 1.0000\n",
            "Epoch 202/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0699 - accuracy: 0.9906\n",
            "Epoch 203/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9969\n",
            "Epoch 204/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 1.0000\n",
            "Epoch 205/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 1.0000\n",
            "Epoch 206/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 1.0000\n",
            "Epoch 207/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 1.0000\n",
            "Epoch 208/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9937\n",
            "Epoch 209/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 210/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 1.0000\n",
            "Epoch 211/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 1.0000\n",
            "Epoch 212/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0481 - accuracy: 1.0000\n",
            "Epoch 213/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 214/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 1.0000\n",
            "Epoch 215/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 1.0000\n",
            "Epoch 216/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 1.0000\n",
            "Epoch 217/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 1.0000\n",
            "Epoch 218/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9937\n",
            "Epoch 219/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 1.0000\n",
            "Epoch 220/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 1.0000\n",
            "Epoch 221/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 1.0000\n",
            "Epoch 222/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9937\n",
            "Epoch 223/240\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 1.0000\n",
            "Epoch 224/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 1.0000\n",
            "Epoch 225/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0429 - accuracy: 1.0000\n",
            "Epoch 226/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 1.0000\n",
            "Epoch 227/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 228/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 229/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 1.0000\n",
            "Epoch 230/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 231/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9969\n",
            "Epoch 232/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0414 - accuracy: 1.0000\n",
            "Epoch 233/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 1.0000\n",
            "Epoch 234/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 1.0000\n",
            "Epoch 235/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 1.0000\n",
            "Epoch 236/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 1.0000\n",
            "Epoch 237/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9969\n",
            "Epoch 238/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9969\n",
            "Epoch 239/240\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 1.0000\n",
            "Epoch 240/240\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Fitting the ANN to the training set\n",
        "history=classifier.fit(x = X_train, y = y_train, batch_size = 24, epochs = 240)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46R6VCMVh1p4",
        "outputId": "c5e184e5-5696-4302-98cf-5f52f3f2717f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, None, None, 32) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 32), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 32).\n"
          ]
        }
      ],
      "source": [
        "# Predicting the Test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MUXkjWph7kH",
        "outputId": "35b70dc0-ba2b-477e-f4e6-5aff3b693175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[28  0]\n",
            " [ 1 51]]\n"
          ]
        }
      ],
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "ckd = confusion_matrix(y_test, y_pred)\n",
        "print(ckd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khyahLFlh-I-",
        "outputId": "b2dc5d30-41cf-43db-ca58-95cb7e9fb471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  98.75\n"
          ]
        }
      ],
      "source": [
        "# Accuracy using confusion matrix\n",
        "accuracy_per = ((ckd[0,0]+ckd[1,1])/len(y_test))\n",
        "print(\"Accuracy: \",accuracy_per * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ytqWunztX012",
        "outputId": "12374ce5-f15c-4287-8ba4-90823ee2504f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyU9bn38c/FrrIoEgMCNkCxiqioAW0R6GkfK26gxY36HMHWWtsHWh8qLnWLSzetWms5KvW4V9FafeSoiNWjVY9iCRiWkFIWUYJSFpVSEYHkev64JmUMAcZkkjuZ+b5fr3nN3DN3Zq6fg9f9m99q7o6IiOS+VkkHICIiTUMJX0QkTyjhi4jkCSV8EZE8oYQvIpIn2iT1wd26dfOioqKkPl5EpEWaM2fOOncvqM/fJpbwi4qKKC0tTerjRURaJDN7p75/qyYdEZE8oYQvIpInlPBFRPJERm34ZjYSuA1oDdzt7r+o9fqtwL+lDvcE9nP3vbMZqIhIXbZu3UplZSWbN29OOpSs6tChA7169aJt27ZZe8/dJnwzaw1MAY4DKoHZZjbd3RfVnOPu/zft/InAEVmLUERkFyorK+nUqRNFRUWYWdLhZIW7s379eiorK+nTp0/W3jeTJp0hwFJ3X+7uW4BpwOhdnD8WeCQbwYmI7M7mzZvZd999cybZA5gZ++67b9Z/tWSS8HsCK9OOK1PP7cDMvgD0Af57J69fYGalZla6du3azxuriEidcinZ12iMMmW70/Zs4HF3r6rrRXef6u7F7l5cUFCveQOwcCFcey1s3NiAMEVE8k8mCX8V0DvtuFfqubqcTWM358yYASUl0K8fvP56o36UiEgmOnbsmHQIGckk4c8G+ptZHzNrRyT16bVPMrODgH2AN7IbYi2TJ8Nf/gJdusCoUbBkSaN+nIhIrthtwnf3bcAEYCZQATzm7uVmdp2ZjUo79WxgmjfFFlqDB0dNv6oKLrmk0T9ORCQT7s7kyZMZOHAghx56KI8++igA77//PsOHD2fQoEEMHDiQV199laqqKsaPH/+vc2+99dZGjy+jcfju/izwbK3nrq51XJK9sDLwxS/Ct78Nt98O69ZBt25N+vEi0gxddBGUlWX3PQcNgl//OqNTn3jiCcrKypg3bx7r1q1j8ODBDB8+nIcffpjjjz+eK664gqqqKjZt2kRZWRmrVq1i4cKFAHz00UfZjbsOLXum7bhxsHUrPKJRoCKSvNdee42xY8fSunVrCgsLGTFiBLNnz2bw4MHce++9lJSUsGDBAjp16kTfvn1Zvnw5EydO5LnnnqNz586NHl9iq2VmxWGHwRFHwIMPwsSJSUcjIknLsCbe1IYPH84rr7zCM888w/jx45k0aRLnnnsu8+bNY+bMmdx555089thj3HPPPY0aR8uu4QOcdBLMnQubNiUdiYjkuWHDhvHoo49SVVXF2rVreeWVVxgyZAjvvPMOhYWFfPe73+X8889n7ty5rFu3jurqasaMGcMNN9zA3LlzGz2+ll3Dh+jAraqCt96CoUOTjkZE8thpp53GG2+8weGHH46ZceONN9K9e3fuv/9+brrpJtq2bUvHjh154IEHWLVqFeeddx7V1dUA/PznP2/0+KwpBtXUpbi42LOyAcr778P++8Ott0aHjYjklYqKCg4++OCkw2gUdZXNzOa4e3F93q/lN+n06AE9e8Ls2UlHIiLSrLX8hA/RrKOELyKyS7mT8JcsgSYYxyoizU9STdONqTHKlBsJ/9BD437x4mTjEJEm16FDB9avX59TSb9mPfwOHTpk9X1b/igdiIXUAJYtg6OPTjYWEWlSvXr1orKyklxbcr1mx6tsyo2EX1QU98uXJxqGiDS9tm3bZnVXqFyWG006e+4Zo3WU8EVEdio3Ej5A375K+CIiu5A7Cb9fPyV8EZFdyJ2E37cvVFbCp58mHYmISLOUWwnfHVasSDoSEZFmKbcSPqhZR0RkJ3In4dcMy3r77WTjEBFppnIn4RcWQqtWsHp10pGIiDRLuZPwW7eOfW2V8EVE6pQ7CR+ge3f4+9+TjkJEpFnKKOGb2UgzW2xmS83ssp2cc6aZLTKzcjN7OLthZqh7d9XwRUR2Yrdr6ZhZa2AKcBxQCcw2s+nuvijtnP7A5cBQd//QzPZrrIB3qbBQK2aKiOxEJjX8IcBSd1/u7luAacDoWud8F5ji7h8CuPua7IaZoZoafg4tkyoiki2ZJPyewMq048rUc+kOBA40s/8xs1lmNrKuNzKzC8ys1MxKG2Up0+7dY6bthg3Zf28RkRYuW522bYD+wFeBscDvzGzv2ie5+1R3L3b34oKCgix9dJrCwrhXx62IyA4ySfirgN5px71Sz6WrBKa7+1Z3fxv4G3EBaFrdu8e9Om5FRHaQScKfDfQ3sz5m1g44G5he65z/R9TuMbNuRBNP069xUFPDV8IXEdnBbhO+u28DJgAzgQrgMXcvN7PrzGxU6rSZwHozWwS8BEx29/WNFfRO1dTw1aQjIrKDjLY4dPdngWdrPXd12mMHJqVuyenaFdq0UQ1fRKQOuTXTtlUr2G8/JXwRkTrkVsIHLa8gIrITuZnwVcMXEdlB7iX8wkIlfBGROuRewu/eHdasgerqpCMREWlWcjPhb9sGH3yQdCQiIs1K7iV8La8gIlKn3Ev4Wl5BRKROSvgiInki9xK+mnREROqUewm/Sxdo3141fBGRWnIv4Ztp8pWISB1yL+FDNOuoSUdE5DNyM+Grhi8isgMlfBGRPJGbCb9HD1i7FrZsSToSEZFmIzcTfu/e4A7vvZd0JCIizUbuJnyAd99NNg4RkWYktxP+ypXJxiEi0owo4YuI5IncTPgdO8Leeyvhi4ikySjhm9lIM1tsZkvN7LI6Xh9vZmvNrCx1Oz/7oX5OvXsr4YuIpGmzuxPMrDUwBTgOqARmm9l0d19U69RH3X1CI8RYPwccoIQvIpImkxr+EGCpuy939y3ANGB044aVBarhi4h8RiYJvyeQnjkrU8/VNsbM5pvZ42bWu643MrMLzKzUzErXrl1bj3A/h969Yf162LSpcT9HRKSFyFan7X8BRe5+GPAn4P66TnL3qe5e7O7FBQUFWfronagZqVNZ2bifIyLSQmSS8FcB6TX2Xqnn/sXd17v7p6nDu4GjshNeAxxwQNy/806ycYiINBOZJPzZQH8z62Nm7YCzgenpJ5hZj7TDUUBF9kKsp7594/7tt5ONQ0SkmdjtKB1332ZmE4CZQGvgHncvN7PrgFJ3nw780MxGAduAD4DxjRhzZvbfH9q1g+XLk45ERKRZ2G3CB3D3Z4Fnaz13ddrjy4HLsxtaA7VuDUVFsGxZ0pGIiDQLuTnTtkbfvqrhi4ikKOGLiOSJ3E/4H30EH36YdCQiIonL/YQPquWLiKCELyKSN/Ij4WukjohIjif8Tp1iQ/OK5OeBiYgkLbcTPsAhh0B5edJRiIgkLj8SfkUFVFcnHYmISKLyI+Fv2gQrViQdiYhIonI/4Q8cGPdq1hGRPJf7CX/AgLhXwheRPJf7Cb9LF+jVSwlfRPJe7id8gEMPhXnzko5CRCRR+ZHwhwyJGv7GjUlHIiKSmPxI+MccE8MyZ89OOhIRkcTkR8I/+ui4nzUr2ThERBKUHwl/n33goIOU8EUkr+VHwodo1nnjDXBPOhIRkUTkT8IfNgzWrYOysqQjERFJRP4k/FNOgVat4I9/TDoSEZFEZJTwzWykmS02s6VmdtkuzhtjZm5mxdkLMUsKCmDECCV8Eclbu034ZtYamAKcAAwAxprZgDrO6wT8CHgz20FmzZgx8Ne/wqJFSUciItLkMqnhDwGWuvtyd98CTANG13He9cAvgc1ZjC+7Tjst7lXLF5E8lEnC7wmsTDuuTD33L2Z2JNDb3Z/JYmzZt//+8JWvKOGLSF5qcKetmbUCbgF+nMG5F5hZqZmVrl27tqEfXT9jxsS6OtrnVkTyTCYJfxXQO+24V+q5Gp2AgcDLZrYCOAaYXlfHrbtPdfdidy8uKCiof9QN8c1vxr1q+SKSZzJJ+LOB/mbWx8zaAWcD02tedPcN7t7N3YvcvQiYBYxy99JGibihioqguFgJX0Tyzm4TvrtvAyYAM4EK4DF3Lzez68xsVGMH2CjGjIG//AXefTfpSEREmkxGbfju/qy7H+ju/dz9p6nnrnb36XWc+9VmW7uvMWZM3D/xRLJxiIg0ofyZaZuuf3847DB46CGoqko6GhGRJpGfCR/gootgzhy49tqkIxERaRL5m/DHj4/b9ddH4hcRyXH5m/DN4LbbYq38a65JOhoRkUaXvwkfoHNnmDwZnnkm1soXEclh+Z3wASZOhB494MILYcuWpKMREWk0SvgdO8Idd8D8+XDTTUlHIyLSaJTwAUaPjpU0f/lLWL8+6WhERBqFEn6N666Df/4Tbr456UhERBqFEn6NgQPhzDPh9ttj71sRkRyjhJ/ummvg44/hV79KOhIRkaxTwk938MEwdmzU8tesSToaEZGsUsKv7eqrYfNmjdgRkZyjhF/bl74E55wDU6bA6tVJRyMikjVK+HW56qqYhHXiiVBennQ0IiJZoYRfl/79Y0esVasi6WsGrojkACX8nRk9Gu6/P3bFeuCBpKMREWkwJfxdOf742P/2hhugoiLpaEREGkQJf1fM4JZb4KOPYoesadOSjkhEpN6U8Hdn2DBYsgS+/GU491x46aWkIxIRqRcl/EwUFMBTT0Vn7qmnwoIFSUckIvK5KeFnap994LnnYjnlM84A96QjEhH5XDJK+GY20swWm9lSM7usjtcvNLMFZlZmZq+Z2YDsh9oM9O4NJSWweLFq+SLS4uw24ZtZa2AKcAIwABhbR0J/2N0PdfdBwI3ALVmPtLk45ZTozH3qqaQjERH5XDKp4Q8Blrr7cnffAkwDRqef4O7/SDvcC8jd9o7u3eHoo+HJJ2PNHRGRFiKThN8TWJl2XJl67jPM7P+Y2TKihv/Dut7IzC4ws1IzK127dm194m0eTj0V3nor2vOnTk06GhGRjGSt09bdp7h7P+BS4MqdnDPV3YvdvbigoCBbH930vvc9+OlPYcgQ+PGPYwkGEZFmLpOEvwronXbcK/XczkwDTm1IUM3e3nvDT34CDz4I27bBWWdpZU0RafYySfizgf5m1sfM2gFnA9PTTzCz/mmHJwFLshdiM9avH9x3H8ydG0swrFwJZWWxN66ISDOz24Tv7tuACcBMoAJ4zN3Lzew6MxuVOm2CmZWbWRkwCRjXaBE3N2edBa+/Dhs3wuGHwxFHwMUXJx2ViMgOzBOaQFRcXOylpaWJfHaj+NOf4DvfgU6doqa/ejXsuWfSUYlIjjGzOe5eXJ+/1UzbbDnuuFhK+T/+I2r7TzyRdEQiIp+hhJ9tw4dD377w299CdXXS0YiI/IsSfraZwZVXwptvwuTJMHGihm2KSLPQJukActL48fDoo7GWPkC7dnDzzYmGJCKiGn5jMIOHHootEk86KR5v3Zp0VCKS55TwG0u3brFhyoUXwpo18OyzSUckInlOCb+xjRwJPXrAbbclHYmI5Dkl/MbWpg1cemlsjXjVVfDNb8Ly5UlHJSJ5SBOvmsLmzbE9YmVlHO+/Pxx7bAzh/MEPos1fRCQDmnjV3HXoEB23P/85lJZC167wP/8DEybE0E0RkSagGn5Sqqujdn/XXbG2/qBBSUckIi2AavgtUatW8ItfxCYqt+TujpAi0nwo4Sdp771jwbVHHoktE7UUg4g0IiX8pF18MfTpE6N3SkrAHT74IOmoRCQHKeEnrVcvWLQoEv4tt8B550HPnhq6KSJZp4TfHLRpA9ddB5s2xXIMmzfDb34Ttf2XX4ZnnonHIiINoMXTmotDDolRO8uWQefO8J//Ca+9BnPmxOtjxsDvfw/t2ycbp4i0WEr4zclvfxv3c+fC44/DP/4BU6fCunWxafqwYfCjHyUbo4i0WEr4zdGRR8Y2iYWF0Lp1PPfii3DDDbH0cpcuiYYnIi2T2vCbq/33357sIWbprlsXI3ruuiu5uESkxVLCbykGD45a/pe+FEM5N2yAqqqkoxKRFiSjhG9mI81ssZktNbPL6nh9kpktMrP5ZvaimX0h+6EKX/saTJkC//wnnH56dO6WlMC2bUlHJiItwG4Tvpm1BqYAJwADgLFmNqDWaW8Bxe5+GPA4cGO2A5WUI4+MVTZfeAEKCuDaa2N5hh/8IOnIRKSZy6SGPwRY6u7L3X0LMA0YnX6Cu7/k7ptSh7OAXtkNUz5jyhS4/nr429/gqadg1Ci4445Yc19EZCcyGaXTE1iZdlwJHL2L878DzKjrBTO7ALgA4IADDsgwRNnBwIFxg0j23/gGzJoFl1wCb7wRE7lERGrJaqetmf1voBi4qa7X3X2quxe7e3FBQUE2Pzq/degQK2+WlsK3vhXLNPzud/GaNk8XkZRMqoKrgN5px71Sz32Gmf0v4ApghLt/mp3wJGPf+lY08Vx7bRz/93/Dp5/CZZdFs8/Xv55sfCKSuN1ugGJmbYC/AV8nEv1s4FvuXp52zhFEZ+1Id1+SyQfn/QYojcEdXn89llkePnz784WFUFYG3bsnF5uIZEWjboDi7tuACcBMoAJ4zN3Lzew6MxuVOu0moCPwBzMrM7Pp9QlGGsgMhg6NJRhGj4a99ora/T/+ETX8Sy6BE0+EioqkIxWRBGiLw1z1ySewfn0sv/zyy3DyybEaZ8eO0a7/9NNq5hFpgbTFoexojz0i2QN89auxIFtFRbTz9+0LZ54Zj0Ukbyjh54sDD4xlGbp3h+mpFrejjoJTTokLwpKMul5EpAVTws9H/frFOvvDh0etf8ECGDECli5NOjIRaUSaoZOviopiJy2AhQujln/KKXDSSfD227FUQ48esULnF78Yq3eKSIumTlsJL78Mxx0XK3Dus89nN1Lv2xfmz49RPyKSqIZ02qqGL+GrX42k36lTNPk8/zxs2RJDOi+4AK68Em69NekoRaQBlPBlu6FDtz8+7bTtj8vK4LbbYhjnySfDW2/FAm5z5sA558DEidprV6QFUMKX3fvVr2JxtrPPjqGeixfDnnvCgAEweXIM75w6NekoRWQ3NEpHdm+PPeDJJ2HkSDjooGjaWbUKZs+GSy+Nhdoeeyza/xcvTjpaEdkJddpKw2zZEkM658yBQYPiIvBf/xVNPyKSdZppK8lp1w5mzIDiYigvj4ldP/kJ/OhH8O//Hks2i0izoIQvDbf33vDnP8O778Itt8RErttvjxm9Rx8dj0Ukceq0lexo2xb23RfOOgv++teYxTtkSNTyf/jD+BVw7LGxnMPxxycdrUheUhu+NK6qqhjSee21Maa/VavYnGXEiKQjE2mRGtKGr4QvTePTTyPhH3ssvPMOtG4N3/52LNlcUREXhPbt4xeAZvSK7JQ6baX5a98eCgqiXX/cODj1VPjtb+GBB2D58tiIfcQIGDx4+yJu8+fHWP8JE2D16hj9k1AFRSQXqIYvySkthc6dY5G2Z5+NIZ4XXRQjfy6/PG5m8PHH8dyWLbHg24knJh25SGLUpCO5o6IiOnzXrYNjjoEnnohRPgsXRo1/v/3gzTfjQjB/PtxxB1x1lVbzlLyhxdMkdxx8MLz0Uozq+eEPoynoZz+L1+6+G777XTj8cOjWLZZ7+OQTePXVGBa6777Jxi7SzKkNX5qfgQNjjZ7aC7KNGxfNPEVFsS/vySfDtGnR5n/iibBx4/Zz//736CguK4uF4Corm7QIIs2RavjScrRtu722n65DBxgzJpZ1Hjo0OoAnTYqLwCefxK+FpUtjTsDIkXDYYU0fu0gzkFEN38xGmtliM1tqZpfV8fpwM5trZtvM7PTshymyC6NHw9NPR4J/9dXYrat9+2j/nzEjXl+6NBZ6+7d/i4XfAKqrk41bpIntNuGbWWtgCnACMAAYa2YDap32LjAeeDjbAYpkZORIuO++2Ix96tRYtbNfvxjTf889sGZNrOO/eXPM9B07NjZ7ufrq7e9RWalhn5LTMqnhDwGWuvtyd98CTANGp5/g7ivcfT6gKpMka599omO3sDDG7T/7LHTtGsl90CB46KEY4fPii/ClL8H118Ndd0UHce/e8NOfxvu88048/uST6Cx+4AFdDKTFy6QNvyewMu24Eji6Ph9mZhcAFwAccMAB9XkLkcwdfHDc0p122vbdvD75BL7yFbjwwjg+6KCo8XfuHL8Systj3P8bb8TrM2dG4m/VKi4a6Vavhi5dYu8AkWaqSTtt3X0qMBViHH5TfrbIDvbYA15/PUbytG0bs3qPPz6Wdm7dOi4MTz4Zs39POglKSuIi8eab8OUvw/jxsHZtJPuSEjj9dLjzzrgwnHZavIdIM5JJwl8F9E477pV6TqTl22OPSN41Xnkl5gG4x8bu994byb5Hj0juU6bEL4Gnn4Y//nH73xUWxhDR9esj4f/mN7HXb7olS2IZiYEDY5mJRx6JJSa6dGmSoorsdqatmbUB/gZ8nUj0s4FvuXt5HefeBzzt7o/v7oM101ZanG3bYoLX8OHw3nvRzt+rV9T6O3eGvn3jnM6dYwTQL34RG78fdFD8Kjj22Hi9S5doSpoxI4aQPvMMtNEIaclMoy6e5u7bgAnATKACeMzdy83sOjMblQpgsJlVAmcAd5nZDhcDkRavTZtI4G3bwhe+EIm/b1845JDo8D3vPDjwwJgB3LFjLPo2cCCccw6ceSb07AnPPx+1+xkz4IQT4vjyy3f9uWVln51UJlJPWktHJFuqq6MG365d3FdWwi9/Gf0A7drFRu/HHBNNQ7NmxUzhiROjmejGG+FrX4NDD40Ly803x+JykyfHrmHf+EaMOILoRO7aNUYZ1e48lpynxdNEWqqtW6Oj+KWX4rh9+2jyWbMmjvfcM5qM3OHBB6Mf4Lrr4rWTT46LyJIl8P3vx9DSs86K17Zta3gz0aZNsTn9sGENex/JKi2eJtJStW0bzTplZfD22zB7diT7YcNi5dCbb47bQw/F0hAA554bTUdXXQX9+8MHH8RFYfbsmIewenXMNn74YRg1qv6x3XorXHnl9n4LafFUwxdprrZtg9dei2S7YUM0Da1eHc08bdvG0hEPPxy/CCZNin6CRYu2zxPo0iXWHurRI5adaNUqbrXdcEOcW3tU0ZAhcRH5ylcijvTmI3c44wzo3j02smkqa9ZETCed1HSf2cyoSUdE4J//hF/9KpaVuPjiWDeoprO3fftYPfSLX4zlJdq3j87iLVvi14AZPPVUDFOt2Y+gZ8/odF64MOYiHHpoLGFxxhkxJPX002PhurVro5P681i0CJ57Li5Un8fkyVHGJUuiLHlITToiEkm3pGT78YoVsY/wvHnw8suxrlBFRSTpxYvh/PPjvKFDY5hpTfPPsGHb5yY89FBsS/nCC3F/773RAT1pUuw/sH59dCafeeauY6uujgtHzUqlJSXwhz9E/8Uhh2RexlmztseVXlbJiGr4IvmoujrmBixYEJO/Vq2Cxx+PJppLLolfAf36RU26piln48ZIzitXRmfyCy/EjOIjjoAf/zj6E7ZujQtP9+6f/bySktio/rHHYjjqfvtFv0NJCVxzzfaYVq6MIa912bo1mp4++WTH2GpceWXU/MePz+J/rOalITV83D2R21FHHeUi0gy9/77788+7L1my42vPPedeVOT+4otx/IMfuEeL/vZbq1buQ4e6jxjh/pOfuN99t3vbtvFa377u990XjwsK3AcO3P7eEye6m7m/8ELdcc2dG393/PFx/+c/7xh3q1buffq4V1dnVtYPP3QfPNj91VczO78ZAEq9nnlXCV9E6m/9evc//CEuAHfc4X7vvZHkjznGfciQSMDgXljo/sAD2y8IPXu6//rXcXzWWdsvHG3auH/hC+7l5e4bN7pv2OD+8cfxWXfcEecsWOC+777uJ5/82Vhuv337RWfu3Mziv/vuOH/cuO3PVVe7X3+9+/z5WfgPlH0NSfhqwxeR+uvaNTpvISaO1bZ+fWw32atXLFHdqlWMsvn616OfYMaMaFqqrIzjG27YsV3fDI46Cj7+OPYyPuSQmHNwzTXRr/DeezFJbdasmPm8YkWsavrxxzHRbVfzEaZNi/tnnoGqqljw7s9/jiGvr74a6yLlELXhi0jyqqq2DyddsSImoq1fH89t2BDHCxdG5/Cdd8bcg3794KOP4u87dIh+h5/9LOY1vPxyPH/ggXGh+fDD6FcYPTpmLm/cGO9x3nmxhHZ5eQw9HTo0LmA1C+OVl8cqqrvy+9/HheGee+q+uNxwQ3zW2WfHUNcG0rBMEck/lZUxYa2wMIaP/ulPsQTF7NkxR2HgwNi8Zq+9ItkvXhy/BGp7440YirrnnnFbswbGjYtEfuyxMRTULIaw9ugRncrt28eFZN68SOJbtsRieZde+tn3fu21GPXUqlUMeV22LOJtACV8EZFMvPdejEzq1ClGE1VXx05o114L8+dHIl+2LGr4jzwSG+Js3lz3e3XrFr8c9tsPDj88foVMmhQXhfbt4xdISUmMJpo5E4qL4Xvfa/BENSV8EZHGsGFD7IXctm3c3n0X3n8/+geWLYtfDuecE30Z558ffQHVtXZ6rdkb4fvfj+aoPn1i+8yxY+sVkiZeiYg0hi5dYiOcGrtqg58+Pdrqq6rigrBiRST/mr+/8cbovC4vj18FCVDCFxHJlq5d476gAIqKPvtap05wxRVNHlK63W6AIiIiuUEJX0QkTyjhi4jkCSV8EZE8oYQvIpInlPBFRPKEEr6ISJ5QwhcRyROJLa1gZmuBd+r5592AdVkMp6VR+fO3/PlcdlD5uwF7uXtBff44sYTfEGZWWt+1JHKByp+/5c/nsoPK39Dyq0lHRCRPKOGLiOSJlprwpyYdQMJU/vyVz2UHlb9B5W+RbfgiIvL5tdQavoiIfE5K+CIieaLFJXwzG2lmi81sqZldlnQ8jc3MVpjZAjMrM7PS1HNdzexPZrYkdb9P0nFmi5ndY2ZrzGxh2nN1ltfCb1L/Fuab2ZHJRZ4dOyl/iZmtSv0bKDOzE9NeuzxV/sVmdnwyUWeHmfU2s5fMbJGZlZvZj1LP58X3v4vyZ+/7d/cWc2YYGm8AAAKqSURBVANaA8uAvkA7YB4wIOm4GrnMK4ButZ67Ebgs9fgy4JdJx5nF8g4HjgQW7q68wInADMCAY4A3k46/kcpfAlxcx7kDUv8PtAf6pP7faJ10GRpQ9h7AkanHnYC/pcqYF9//Lsqfte+/pdXwhwBL3X25u28BpgGjE44pCaOB+1OP7wdOTTCWrHL3V4APaj29s/KOBh7wMAvY28x6NE2kjWMn5d+Z0cA0d//U3d8GlhL/j7RI7v6+u89NPd4IVAA9yZPvfxfl35nP/f23tITfE1iZdlzJrv+D5AIHnjezOWZ2Qeq5Qnd/P/V4NVCYTGhNZmflzad/DxNSzRb3pDXh5Wz5zawIOAJ4kzz8/muVH7L0/be0hJ+PjnX3I4ETgP9jZsPTX/T4bZc3Y2vzrbwpdwD9gEHA+8DNyYbTuMysI/BH4CJ3/0f6a/nw/ddR/qx9/y0t4a8Ceqcd90o9l7PcfVXqfg3wJPGT7e81P11T92uSi7BJ7Ky8efHvwd3/7u5V7l4N/I7tP9tzrvxm1pZIdr939ydST+fN919X+bP5/be0hD8b6G9mfcysHXA2MD3hmBqNme1lZp1qHgPfABYSZR6XOm0c8FQyETaZnZV3OnBuarTGMcCGtJ/+OaNWu/RpxL8BiPKfbWbtzawP0B/4S1PHly1mZsB/AhXufkvaS3nx/e+s/Fn9/pPuma5HT/aJRO/1MuCKpONp5LL2JXrh5wHlNeUF9gVeBJYALwBdk441i2V+hPjZupVok/zOzspLjM6Ykvq3sAAoTjr+Rir/g6nyzU/9T94j7fwrUuVfDJyQdPwNLPuxRHPNfKAsdTsxX77/XZQ/a9+/llYQEckTLa1JR0RE6kkJX0QkTyjhi4jkCSV8EZE8oYQvIpInlPBFRPKEEr6ISJ74/1BMtvhE8aBjAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# looking the loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'],\"r\", label='loss')     # loss of train\n",
        " \n",
        "           \n",
        "plt.legend()  # show label\n",
        "plt.show()    # show picture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(10,8))          # 定義一個視窗(10,8 為視窗大小)\n",
        "plt.subplots_adjust(hspace = 0.3)   # 調整兩張圖的間距\n",
        "\n",
        "# 實際值-預測值(*max(label)表示恢復原始值)\n",
        "error=y_test.reshape(30,1)*max(label)-model.predict(y_test)*max(label)\n",
        "# 把誤差分成 15 等份, 求出每一等份的長度\n",
        "step=(max(error)-min(error))/15\n",
        "# 寫出每一等份的值    \n",
        "interval=[i for i in range(int(min(error)),\n",
        "                           int(max(error))+int(step),\n",
        "                           int(step))]\n",
        "\n",
        "# 實際預測比較圖\n",
        "width = 0.3\n",
        "plt.subplot(2,1,1)      # 第一張圖位於視窗裡的位置 (2列1行的第二個位置 - 上)\n",
        "plt.xlabel(\"test data\") # x軸名稱\n",
        "plt.ylabel(\"money\")                             # y軸名稱\n",
        "plt.bar(np.linspace(1,30,30)-width/2,           # 實際值\n",
        "        (test_label*max(label)).reshape(30),\n",
        "        width=width, label='actual')                \n",
        "plt.bar(np.linspace(1,30,30)+width/2,           # 預測值\n",
        "        (model.predict(test_data)*max(label)).reshape(30),\n",
        "        width=width, label='predict') \n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# 誤差分布圖\n",
        "plt.subplot(2,1,2)      # 第二張圖位於視窗裡的位置 (2列1行的第二個位置 - 下)\n",
        "plt.xlabel(\"error\")     # x軸名稱\n",
        "plt.ylabel(\"quantity\")  # y軸名稱\n",
        "plt.hist(error,interval,linewidth=1,edgecolor='black')   #顯示\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2v4fG51rlGrI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ann_ckd.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}